{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gulls-guide.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM0Qr60CpDT5/0XWvvmHIJj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l_IP8mUHKSs",
        "colab_type": "text"
      },
      "source": [
        "#Convolutional Neural Network for identifying 3 most commonly mistaken species of gulls in Poland - *Larus argentatus*, *Larus cachinnans* and *Larus michachellis*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Scq6n-D5LbfJ",
        "colab_type": "text"
      },
      "source": [
        "<table align=\"center\">\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/bazylip/gulls-ai-guide/blob/master/gulls_guide.ipynb\">\n",
        "        <img src=\"http://introtodeeplearning.com/images/colab/colab.png?v2.0\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/bazylip/gulls-ai-guide/blob/master/gulls_guide.ipynb\">\n",
        "        <img src=\"http://introtodeeplearning.com/images/colab/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P-8tEUIHE4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Tensorflow 2.0\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "from PIL import Image, ImageOps, ImageFile\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import collections\n",
        "\n",
        "# Check that we are using a GPU, if not switch runtimes\n",
        "#   using Runtime > Change Runtime Type > GPU\n",
        "assert len(tf.config.list_physical_devices('GPU')) > 0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wah-T8cgJeP8",
        "colab_type": "text"
      },
      "source": [
        "Download images from [Gull Research website](http://www.gull-research.org/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LzQeNBKJdtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "urls = ['http://www.gull-research.org/hg/hg1cy/', 'http://www.gull-research.org/hg/hg2cy/',\n",
        "        'http://www.gull-research.org/hg/hg3cy/', 'http://www.gull-research.org/hg/hg4cy/',\n",
        "        'http://www.gull-research.org/hg/hg5cy/']\n",
        "image_urls = collections.defaultdict(list)\n",
        "\n",
        "def list_files(url, ext='html'):\n",
        "    page = requests.get(url).text\n",
        "    soup = BeautifulSoup(page, 'html.parser')\n",
        "    return [url + node.get('href') for node in soup.find_all('a') if node.get('href').endswith(ext)]\n",
        "  \n",
        "def get_all_image_urls(site):\n",
        "    response = requests.get(site)\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    img_tags = soup.find_all('img')\n",
        "\n",
        "    urls = [img['src'] for img in img_tags]\n",
        "    image_urls = []\n",
        "    for url in urls:\n",
        "        filename = re.search(r'/([\\w_-]+[.](jpg|png|JPG|PNG))$', url)\n",
        "        if not filename:\n",
        "            continue\n",
        "        if 'http' not in url:\n",
        "            # sometimes an image source can be relative \n",
        "            # if it is provide the base url which also happens \n",
        "            # to be the site variable atm.\n",
        "            site_level_below = '/'.join(site.split('/')[:-2])\n",
        "            url_with_no_dots = '/'.join(url.split('/')[1:]) \n",
        "            url = f\"{site_level_below}/{url_with_no_dots}\"\n",
        "        image_urls.append(url)\n",
        "    return image_urls\n",
        "\n",
        "for age, url in enumerate(urls):\n",
        "  for site in list_files(url):\n",
        "    urls_from_site = get_all_image_urls(site)\n",
        "    \n",
        "    if urls_from_site is not None:\n",
        "      for image_url in urls_from_site:\n",
        "        image_urls[age+1].append(image_url)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOxpw2EVeUmw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "aa39c205-6a0d-4abf-ec79-450181a0154d"
      },
      "source": [
        "for age in image_urls.keys():\n",
        "  print(f\"Images for age {age}: {len(image_urls[age])}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images for age 1: 1438\n",
            "Images for age 2: 1802\n",
            "Images for age 3: 1258\n",
            "Images for age 4: 1201\n",
            "Images for age 5: 1731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv6NwXkMkkpB",
        "colab_type": "text"
      },
      "source": [
        "Download the images and turn them into np.array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44_9KX-flEZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = (400, 400)\n",
        "images_and_labels = []\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "for age in image_urls.keys():\n",
        "  for url in image_urls[age]:\n",
        "    try:\n",
        "      response = requests.get(url)\n",
        "      img = Image.open(BytesIO(response.content))\n",
        "      square_size = max(img.size)\n",
        "\n",
        "      img_square = ImageOps.fit(img, (square_size, square_size), Image.ANTIALIAS)\n",
        "      img_resized = img_square.resize(size, Image.ANTIALIAS)\n",
        "\n",
        "      img_array = np.asarray(img_resized)\n",
        "      images_and_labels.append((img_array, age))\n",
        "    except:\n",
        "      pass\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2cnzSFMwEhf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c802af22-f06b-424d-cd16-f6ea5a8694fe"
      },
      "source": [
        "for tup in images_and_labels:\n",
        "  if tup[0].shape != (400,400,3):\n",
        "    images_and_labels.remove(tup)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4SCNY3ydiTr",
        "colab_type": "text"
      },
      "source": [
        "Now divide the images and labels into train set and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2JUgRL-cC6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.shuffle(images_and_labels)\n",
        "train_set_size = 1000\n",
        "\n",
        "train_images = np.asarray([tup[0] for tup in images_and_labels][:-train_set_size])\n",
        "train_labels = np.asarray([tup[1]-1 for tup in images_and_labels][:-train_set_size])\n",
        "\n",
        "test_images = np.asarray([tup[0] for tup in images_and_labels][-train_set_size:])\n",
        "test_labels = np.asarray([tup[1]-1 for tup in images_and_labels][-train_set_size:])\n",
        "\n",
        "print(f\"Length of training set: {len(train_images)}\")\n",
        "print(f\"Length of test set: {len(test_images)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPcD3K_IfaXa",
        "colab_type": "text"
      },
      "source": [
        "Let's see some example pictures from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjWvH-GTffmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def numpy2pil(np_array):\n",
        "    assert_msg = 'Input shall be a HxWx3 ndarray'\n",
        "    assert isinstance(np_array, np.ndarray), assert_msg\n",
        "    assert len(np_array.shape) == 3, assert_msg\n",
        "    assert np_array.shape[2] == 3, assert_msg\n",
        "\n",
        "    img = Image.fromarray(np_array, 'RGB')\n",
        "    return img\n",
        "\n",
        "display(numpy2pil(train_images[0]))\n",
        "print(train_labels[0]+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK9LYgj2hq64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "random_inds = np.random.choice(4000,9)\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    image_ind = random_inds[i]\n",
        "    plt.imshow(np.squeeze(train_images[image_ind]), cmap=plt.cm.binary)\n",
        "    plt.xlabel(f\"Age {train_labels[image_ind]+1}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYRiX9vbjg7Z",
        "colab_type": "text"
      },
      "source": [
        "Let's get to work and build the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7AHCi_ejjJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_cnn_model():\n",
        "    cnn_model = tf.keras.Sequential([\n",
        "        tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(size[0], size[1], 3)),\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters=24, kernel_size=3, activation='relu'), \n",
        "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "        tf.keras.layers.Conv2D(filters=36, kernel_size=3, activation='relu'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(5, activation=tf.nn.sigmoid)\n",
        "    ])\n",
        "    \n",
        "    return cnn_model\n",
        "  \n",
        "cnn_model = build_cnn_model()\n",
        "\n",
        "cnn_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-1), \n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "print(cnn_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5EH1qsrlzpI",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frnDgwGil1KD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5\n",
        "\n",
        "cnn_model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJtrOzedwjhd",
        "colab_type": "text"
      },
      "source": [
        "Check accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri-9Ng_LwiUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_acc = cnn_model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbds_OyDwlAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = cnn_model.predict(test_images)\n",
        "print(f\"Predicted label: {predictions[0].argmax()}\")\n",
        "print(f\"Actual label: {test_labels[0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}